{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBreadth-First Search - Minimum Cost:\u001b[39m\u001b[38;5;124m\"\u001b[39m, breadth_first_cost)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 84\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     83\u001b[0m   file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata0.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 84\u001b[0m   vertices, parent_sets \u001b[38;5;241m=\u001b[39m \u001b[43mread_dataset_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m   \u001b[38;5;66;03m# Call the search algorithm\u001b[39;00m\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;66;03m# best_first_ordering, best_first_cost = best_first_search(vertices, parent_sets)\u001b[39;00m\n\u001b[0;32m     88\u001b[0m   \u001b[38;5;66;03m# depth_first_ordering, depth_first_cost = depth_first_search(vertices, parent_sets)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m   breadth_first_ordering, breadth_first_cost \u001b[38;5;241m=\u001b[39m breadth_first_search(vertices, parent_sets)\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mread_dataset_from_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     22\u001b[0m     parents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit())) \u001b[38;5;28;01mif\u001b[39;00m line[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[0;32m     23\u001b[0m     cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(line[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mparent_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_vertex\u001b[49m\u001b[43m]\u001b[49m[parents] \u001b[38;5;241m=\u001b[39m cost\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid line:\u001b[39m\u001b[38;5;124m\"\u001b[39m, line)\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import heapq\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Getting data from txt file\n",
    "def read_dataset_from_file(file_path):\n",
    "    vertices = {}\n",
    "    parent_sets = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        current_vertex = None\n",
    "        for line in file:\n",
    "            line = line.strip().split(',')\n",
    "            if len(line) == 1:\n",
    "                # New vertex section\n",
    "                current_vertex = int(line[0])\n",
    "                vertices[current_vertex] = {}\n",
    "                parent_sets[current_vertex] = {}\n",
    "            elif len(line) == 3:\n",
    "                # Parent set and cost information\n",
    "                parents = tuple(map(int, line[1][1:-1].split())) if line[1] != '{}' else ()\n",
    "                cost = float(line[2])\n",
    "                parent_sets[current_vertex][parents] = cost\n",
    "            else:\n",
    "                print(\"Invalid line:\", line)\n",
    "\n",
    "    return vertices, parent_sets\n",
    "\n",
    "# Function to calculate the cost of a given ordering\n",
    "def calculate_total_cost(ordering, vertices, parent_sets):\n",
    "    total_cost = 0\n",
    "    for i, vertex in enumerate(ordering):\n",
    "        parent_set = parent_sets[vertex]\n",
    "        consistent_parents = [p for p in parent_set if ordering.index(p) < i]\n",
    "        total_cost += vertices[vertex][tuple(consistent_parents)]\n",
    "    return total_cost\n",
    "\n",
    "# Function to check if a parent set is consistent with an ordering\n",
    "def is_consistent(ordering, vertex, parent_set):\n",
    "    return all(parent in ordering[:ordering.index(vertex)] for parent in parent_set)\n",
    "\n",
    "# Function for generating all possible orderings\n",
    "def generate_orderings(vertices):\n",
    "    return list(itertools.permutations(vertices))\n",
    "\n",
    "# Best-First Search Algorithm\n",
    "def best_first_search(vertices, parent_sets):\n",
    "    orderings = generate_orderings(vertices.keys())\n",
    "    priority_queue = []\n",
    "\n",
    "    for ordering in orderings:\n",
    "        cost = calculate_total_cost(ordering, vertices, parent_sets)\n",
    "        heapq.heappush(priority_queue, (cost, ordering))\n",
    "\n",
    "    return heapq.heappop(priority_queue)\n",
    "\n",
    "# Depth-First Search Algorithm\n",
    "def depth_first_search(vertices, parent_sets):\n",
    "    orderings = generate_orderings(vertices.keys())\n",
    "    stack = []\n",
    "\n",
    "    for ordering in orderings:\n",
    "        cost = calculate_total_cost(ordering, vertices, parent_sets)\n",
    "        stack.append((cost, ordering))\n",
    "\n",
    "    return stack.pop()\n",
    "\n",
    "# Breadth-First Search Algorithm\n",
    "def breadth_first_search(vertices, parent_sets):\n",
    "    orderings = generate_orderings(vertices.keys())\n",
    "    queue = deque()\n",
    "\n",
    "    for ordering in orderings:\n",
    "        cost = calculate_total_cost(ordering, vertices, parent_sets)\n",
    "        queue.append((cost, ordering))\n",
    "\n",
    "    return queue.popleft()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \n",
    "  file_path = \"data0.txt\"\n",
    "  vertices, parent_sets = read_dataset_from_file(file_path)\n",
    "\n",
    "  # Call the search algorithm\n",
    "  # best_first_ordering, best_first_cost = best_first_search(vertices, parent_sets)\n",
    "  # depth_first_ordering, depth_first_cost = depth_first_search(vertices, parent_sets)\n",
    "  breadth_first_ordering, breadth_first_cost = breadth_first_search(vertices, parent_sets)\n",
    "\n",
    "  # Print results\n",
    "  # print(\"Best-First Search - Best Ordering:\", best_first_ordering)\n",
    "  # print(\"Best-First Search - Minimum Cost:\", best_first_cost  \n",
    "  # print(\"Depth-First Search - Best Ordering:\", depth_first_ordering)\n",
    "  # print(\"Depth-First Search - Minimum Cost:\", depth_first_cost  \n",
    "  print(\"Breadth-First Search - Best Ordering:\", breadth_first_ordering)\n",
    "  print(\"Breadth-First Search - Minimum Cost:\", breadth_first_cost)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
