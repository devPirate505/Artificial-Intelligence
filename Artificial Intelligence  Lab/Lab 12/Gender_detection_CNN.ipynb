{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6846122,"sourceType":"datasetVersion","datasetId":3935781}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T16:27:12.825465Z","iopub.execute_input":"2024-05-08T16:27:12.826005Z","iopub.status.idle":"2024-05-08T16:27:12.834557Z","shell.execute_reply.started":"2024-05-08T16:27:12.825965Z","shell.execute_reply":"2024-05-08T16:27:12.832770Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Defining paths to training and validation directories\ntrain_dir = '/kaggle/input/gender-detection-and-classification-image-dataset/train'\nvalidation_dir = '/kaggle/input/gender-detection-and-classification-image-dataset/test'\n\n# Defining image dimensions and batch size\nimage_size = (100, 100)\nbatch_size = 32\n\n# Use ImageDataGenerator for loading and preprocessing images\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,  # Rescale pixel values to [0, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n# Load and preprocess training images from folders\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'  # Assuming a binary classification task (men vs. women)\n)\n\n# ImageDataGenerator for validation data\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and preprocess validation images from folders\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'  # Assuming a binary classification task\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:25:07.690387Z","iopub.execute_input":"2024-05-08T16:25:07.690990Z","iopub.status.idle":"2024-05-08T16:25:07.769333Z","shell.execute_reply.started":"2024-05-08T16:25:07.690946Z","shell.execute_reply":"2024-05-08T16:25:07.768160Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 220 images belonging to 2 classes.\nFound 80 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:27:17.274649Z","iopub.execute_input":"2024-05-08T16:27:17.275136Z","iopub.status.idle":"2024-05-08T16:27:17.457196Z","shell.execute_reply.started":"2024-05-08T16:27:17.275093Z","shell.execute_reply":"2024-05-08T16:27:17.455234Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, epochs=10, batch_size=32, validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:30:05.886584Z","iopub.execute_input":"2024-05-08T16:30:05.887820Z","iopub.status.idle":"2024-05-08T16:36:19.063894Z","shell.execute_reply.started":"2024-05-08T16:30:05.887772Z","shell.execute_reply":"2024-05-08T16:36:19.062584Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.4942 - loss: 0.7120 - val_accuracy: 0.5000 - val_loss: 0.6949\nEpoch 2/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - accuracy: 0.5225 - loss: 0.6963 - val_accuracy: 0.5000 - val_loss: 0.6927\nEpoch 3/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.5116 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6924\nEpoch 4/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4833 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6922\nEpoch 5/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5039 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6919\nEpoch 6/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.5329 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6916\nEpoch 7/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.4746 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6920\nEpoch 8/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4709 - loss: 0.6959 - val_accuracy: 0.5125 - val_loss: 0.6922\nEpoch 9/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.5614 - loss: 0.6919 - val_accuracy: 0.5125 - val_loss: 0.6917\nEpoch 10/10\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.5777 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6910\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(validation_generator)\nprint(f'Validation Accuracy: {accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:36:22.265585Z","iopub.execute_input":"2024-05-08T16:36:22.266016Z","iopub.status.idle":"2024-05-08T16:36:38.699357Z","shell.execute_reply.started":"2024-05-08T16:36:22.265983Z","shell.execute_reply":"2024-05-08T16:36:38.697969Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4648 - loss: 0.6923\nValidation Accuracy: 0.5\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:36:57.301266Z","iopub.execute_input":"2024-05-08T16:36:57.301767Z","iopub.status.idle":"2024-05-08T16:37:14.092767Z","shell.execute_reply.started":"2024-05-08T16:36:57.301730Z","shell.execute_reply":"2024-05-08T16:37:14.091436Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:37:22.797386Z","iopub.execute_input":"2024-05-08T16:37:22.797924Z","iopub.status.idle":"2024-05-08T16:37:22.810720Z","shell.execute_reply.started":"2024-05-08T16:37:22.797882Z","shell.execute_reply":"2024-05-08T16:37:22.809096Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[0.50715667],\n       [0.5053969 ],\n       [0.5107327 ],\n       [0.5116716 ],\n       [0.50893325],\n       [0.5110974 ],\n       [0.51087636],\n       [0.5066558 ],\n       [0.50933456],\n       [0.5083706 ],\n       [0.5052054 ],\n       [0.5039155 ],\n       [0.50804573],\n       [0.5046945 ],\n       [0.5088763 ],\n       [0.5074803 ],\n       [0.507514  ],\n       [0.51037586],\n       [0.51186424],\n       [0.50894815],\n       [0.5077983 ],\n       [0.5131002 ],\n       [0.50722283],\n       [0.509848  ],\n       [0.5142778 ],\n       [0.5105227 ],\n       [0.5119169 ],\n       [0.5079975 ],\n       [0.51141524],\n       [0.50776494],\n       [0.508002  ],\n       [0.50727934],\n       [0.50806695],\n       [0.50861424],\n       [0.5156371 ],\n       [0.5110659 ],\n       [0.5053117 ],\n       [0.51251966],\n       [0.5110243 ],\n       [0.5025274 ],\n       [0.5073242 ],\n       [0.5037189 ],\n       [0.503886  ],\n       [0.5085527 ],\n       [0.51037395],\n       [0.50502074],\n       [0.5123436 ],\n       [0.50695884],\n       [0.508169  ],\n       [0.5080348 ],\n       [0.50825244],\n       [0.5113644 ],\n       [0.5360701 ],\n       [0.51010495],\n       [0.5033813 ],\n       [0.5045349 ],\n       [0.51174104],\n       [0.51124436],\n       [0.50328887],\n       [0.50851846],\n       [0.51009065],\n       [0.50434583],\n       [0.51264524],\n       [0.5101035 ],\n       [0.5112309 ],\n       [0.51232386],\n       [0.5133848 ],\n       [0.5177599 ],\n       [0.5094238 ],\n       [0.51042545],\n       [0.5088749 ],\n       [0.50728244],\n       [0.5102867 ],\n       [0.5085021 ],\n       [0.5060671 ],\n       [0.50782526],\n       [0.5123348 ],\n       [0.50445294],\n       [0.51022893],\n       [0.5066406 ]], dtype=float32)"},"metadata":{}}]}]}